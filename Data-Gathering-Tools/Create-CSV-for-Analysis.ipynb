{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape For CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv '01-01-2020.csv' was not found\n",
      "The csv '01-02-2020.csv' was not found\n",
      "The csv '01-03-2020.csv' was not found\n",
      "The csv '01-04-2020.csv' was not found\n",
      "The csv '01-05-2020.csv' was not found\n",
      "The csv '01-06-2020.csv' was not found\n",
      "The csv '01-07-2020.csv' was not found\n",
      "The csv '01-08-2020.csv' was not found\n",
      "The csv '01-09-2020.csv' was not found\n",
      "The csv '01-10-2020.csv' was not found\n",
      "The csv '01-11-2020.csv' was not found\n",
      "The csv '01-12-2020.csv' was not found\n",
      "The csv '01-13-2020.csv' was not found\n",
      "The csv '01-14-2020.csv' was not found\n",
      "The csv '01-15-2020.csv' was not found\n",
      "The csv '01-16-2020.csv' was not found\n",
      "The csv '01-17-2020.csv' was not found\n",
      "The csv '01-18-2020.csv' was not found\n",
      "The csv '01-19-2020.csv' was not found\n",
      "The csv '01-20-2020.csv' was not found\n",
      "The csv '01-21-2020.csv' was not found\n",
      "The csv '02-30-2020.csv' was not found\n",
      "The csv '02-31-2020.csv' was not found\n",
      "The csv '04-31-2020.csv' was not found\n",
      "The csv '06-31-2020.csv' was not found\n",
      "The csv '09-31-2020.csv' was not found\n",
      "The csv '11-29-2020.csv' was not found\n",
      "The csv '11-30-2020.csv' was not found\n",
      "The csv '11-31-2020.csv' was not found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Record Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>FIPS,Admin2,Province_State,Country_Region,Last...</td>\n",
       "      <td>11-28-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>,,,Afghanistan,2020-11-29 05:25:55,33.93911,67...</td>\n",
       "      <td>11-28-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>,,,Albania,2020-11-29 05:25:55,41.1533,20.1683...</td>\n",
       "      <td>11-28-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>,,,Algeria,2020-11-29 05:25:55,28.0339,1.6596,...</td>\n",
       "      <td>11-28-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>,,,Andorra,2020-11-29 05:25:55,42.5063,1.5218,...</td>\n",
       "      <td>11-28-2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0                                                  1 Record Date\n",
       "0 NaN  FIPS,Admin2,Province_State,Country_Region,Last...  11-28-2020\n",
       "1 NaN  ,,,Afghanistan,2020-11-29 05:25:55,33.93911,67...  11-28-2020\n",
       "2 NaN  ,,,Albania,2020-11-29 05:25:55,41.1533,20.1683...  11-28-2020\n",
       "3 NaN  ,,,Algeria,2020-11-29 05:25:55,28.0339,1.6596,...  11-28-2020\n",
       "4 NaN  ,,,Andorra,2020-11-29 05:25:55,42.5063,1.5218,...  11-28-2020"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Thanks to the website at GitHub for the data!\n",
    "data_url = \"https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "data_dfs = []\n",
    "data_count = 0\n",
    "\n",
    "for x in range(0, 11):\n",
    "    for y in range(31):\n",
    "        if x < 9:\n",
    "            if y < 9:\n",
    "                csv_name = f\"0{x + 1}-0{y + 1}-2020.csv\"\n",
    "                record_date = f\"0{x + 1}-0{y + 1}-2020\"\n",
    "            else:\n",
    "                csv_name = f\"0{x + 1}-{y + 1}-2020.csv\"                \n",
    "                record_date = f\"0{x + 1}-{y + 1}-2020\"\n",
    "        elif y < 9:\n",
    "            csv_name = f\"{x + 1}-0{y + 1}-2020.csv\"\n",
    "            record_date = f\"{x + 1}-0{y + 1}-2020\"\n",
    "        else:\n",
    "            csv_name = f\"{x + 1}-{y + 1}-2020.csv\"                \n",
    "            record_date = f\"{x + 1}-{y + 1}-2020\"\n",
    "\n",
    "        try:\n",
    "            data_tables = pd.read_html(data_url + csv_name)\n",
    "            data_tables[0]['Record Date'] = [f\"{record_date}\"]*(data_tables[0].count().max())\n",
    "            data_dfs.append(data_tables[0])\n",
    "            data_count += 1\n",
    "        except:\n",
    "            print(f\"The csv '{csv_name}' was not found\")\n",
    "\n",
    "data_dfs[-1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column 'FIPS' is not in dataframe 0\n",
      "The column 'FIPS' is not in dataframe 1\n",
      "The column 'FIPS' is not in dataframe 2\n",
      "The column 'FIPS' is not in dataframe 3\n",
      "The column 'FIPS' is not in dataframe 4\n",
      "The column 'FIPS' is not in dataframe 5\n",
      "The column 'FIPS' is not in dataframe 6\n",
      "The column 'FIPS' is not in dataframe 7\n",
      "The column 'FIPS' is not in dataframe 8\n",
      "The column 'FIPS' is not in dataframe 9\n",
      "The column 'FIPS' is not in dataframe 10\n",
      "The column 'FIPS' is not in dataframe 11\n",
      "The column 'FIPS' is not in dataframe 12\n",
      "The column 'FIPS' is not in dataframe 13\n",
      "The column 'FIPS' is not in dataframe 14\n",
      "The column 'FIPS' is not in dataframe 15\n",
      "The column 'FIPS' is not in dataframe 16\n",
      "The column 'FIPS' is not in dataframe 17\n",
      "The column 'FIPS' is not in dataframe 18\n",
      "The column 'FIPS' is not in dataframe 19\n",
      "The column 'FIPS' is not in dataframe 20\n",
      "The column 'FIPS' is not in dataframe 21\n",
      "The column 'FIPS' is not in dataframe 22\n",
      "The column 'FIPS' is not in dataframe 23\n",
      "The column 'FIPS' is not in dataframe 24\n",
      "The column 'FIPS' is not in dataframe 25\n",
      "The column 'FIPS' is not in dataframe 26\n",
      "The column 'FIPS' is not in dataframe 27\n",
      "The column 'FIPS' is not in dataframe 28\n",
      "The column 'FIPS' is not in dataframe 29\n",
      "The column 'FIPS' is not in dataframe 30\n",
      "The column 'FIPS' is not in dataframe 31\n",
      "The column 'FIPS' is not in dataframe 32\n",
      "The column 'FIPS' is not in dataframe 33\n",
      "The column 'FIPS' is not in dataframe 34\n",
      "The column 'FIPS' is not in dataframe 35\n",
      "The column 'FIPS' is not in dataframe 36\n",
      "The column 'FIPS' is not in dataframe 37\n",
      "The column 'FIPS' is not in dataframe 38\n",
      "The column 'FIPS' is not in dataframe 39\n",
      "The column 'FIPS' is not in dataframe 40\n",
      "The column 'FIPS' is not in dataframe 41\n",
      "The column 'FIPS' is not in dataframe 42\n",
      "The column 'FIPS' is not in dataframe 43\n",
      "The column 'FIPS' is not in dataframe 44\n",
      "The column 'FIPS' is not in dataframe 45\n",
      "The column 'FIPS' is not in dataframe 46\n",
      "The column 'FIPS' is not in dataframe 47\n",
      "The column 'FIPS' is not in dataframe 48\n",
      "The column 'FIPS' is not in dataframe 49\n",
      "The column 'FIPS' is not in dataframe 50\n",
      "The column 'FIPS' is not in dataframe 51\n",
      "The column 'FIPS' is not in dataframe 52\n",
      "The column 'FIPS' is not in dataframe 53\n",
      "The column 'FIPS' is not in dataframe 54\n",
      "The column 'FIPS' is not in dataframe 55\n",
      "The column 'FIPS' is not in dataframe 56\n",
      "The column 'FIPS' is not in dataframe 57\n",
      "The column 'FIPS' is not in dataframe 58\n",
      "The column 'FIPS' is not in dataframe 59\n",
      "The column 'Unnamed: 0' is not in dataframe 178\n",
      "The column 'Unnamed: 0' is not in dataframe 179\n",
      "The column 'Unnamed: 0' is not in dataframe 180\n",
      "The column 'Unnamed: 0' is not in dataframe 181\n",
      "The column 'Unnamed: 0' is not in dataframe 182\n",
      "The column 'Unnamed: 0' is not in dataframe 183\n",
      "The column 'Unnamed: 0' is not in dataframe 184\n",
      "The column 'Unnamed: 0' is not in dataframe 185\n",
      "The column 'Unnamed: 0' is not in dataframe 186\n",
      "The column 'Unnamed: 0' is not in dataframe 187\n",
      "The column 'Unnamed: 0' is not in dataframe 188\n",
      "The column 'Unnamed: 0' is not in dataframe 189\n",
      "The column 'Unnamed: 0' is not in dataframe 190\n",
      "The column 'Unnamed: 0' is not in dataframe 191\n",
      "The column 'Unnamed: 0' is not in dataframe 192\n",
      "The column 'Unnamed: 0' is not in dataframe 193\n",
      "The column 'Unnamed: 0' is not in dataframe 194\n",
      "The column 'Unnamed: 0' is not in dataframe 195\n",
      "The column 'Unnamed: 0' is not in dataframe 196\n",
      "The column 'Unnamed: 0' is not in dataframe 197\n",
      "The column 'Unnamed: 0' is not in dataframe 198\n",
      "The column 'Unnamed: 0' is not in dataframe 199\n",
      "The column 'Unnamed: 0' is not in dataframe 200\n",
      "The column 'Unnamed: 0' is not in dataframe 201\n",
      "The column 'Unnamed: 0' is not in dataframe 202\n",
      "The column 'Unnamed: 0' is not in dataframe 203\n",
      "The column 'Unnamed: 0' is not in dataframe 204\n",
      "The column 'Unnamed: 0' is not in dataframe 205\n",
      "The column 'Unnamed: 0' is not in dataframe 206\n",
      "The column 'Unnamed: 0' is not in dataframe 207\n",
      "The column 'Unnamed: 0' is not in dataframe 208\n",
      "The column 'Unnamed: 0' is not in dataframe 210\n",
      "The column 'Unnamed: 0' is not in dataframe 211\n",
      "The column 'Unnamed: 0' is not in dataframe 212\n",
      "The column 'Unnamed: 0' is not in dataframe 213\n",
      "The column 'Unnamed: 0' is not in dataframe 214\n",
      "The column 'Unnamed: 0' is not in dataframe 215\n",
      "The column 'Unnamed: 0' is not in dataframe 216\n",
      "The column 'Unnamed: 0' is not in dataframe 217\n",
      "The column 'Unnamed: 0' is not in dataframe 218\n",
      "The column 'Unnamed: 0' is not in dataframe 219\n",
      "The column 'Unnamed: 0' is not in dataframe 220\n",
      "The column 'Unnamed: 0' is not in dataframe 221\n",
      "The column 'Unnamed: 0' is not in dataframe 222\n",
      "The column 'Unnamed: 0' is not in dataframe 223\n",
      "The column 'Unnamed: 0' is not in dataframe 224\n",
      "The column 'Unnamed: 0' is not in dataframe 225\n",
      "The column 'Unnamed: 0' is not in dataframe 226\n",
      "The column 'Unnamed: 0' is not in dataframe 227\n",
      "The column 'Unnamed: 0' is not in dataframe 228\n",
      "The column 'Unnamed: 0' is not in dataframe 229\n",
      "The column 'Unnamed: 0' is not in dataframe 230\n",
      "The column 'Unnamed: 0' is not in dataframe 231\n",
      "The column 'Unnamed: 0' is not in dataframe 232\n",
      "The column 'Unnamed: 0' is not in dataframe 233\n",
      "The column 'Unnamed: 0' is not in dataframe 234\n",
      "The column 'Unnamed: 0' is not in dataframe 236\n",
      "The column 'Unnamed: 0' is not in dataframe 237\n",
      "The column 'Unnamed: 0' is not in dataframe 250\n",
      "The column 'Unnamed: 0' is not in dataframe 251\n",
      "The column 'Unnamed: 0' is not in dataframe 252\n",
      "The column 'Unnamed: 0' is not in dataframe 253\n",
      "The column 'Unnamed: 0' is not in dataframe 254\n",
      "The column 'Unnamed: 0' is not in dataframe 255\n",
      "The column 'Unnamed: 0' is not in dataframe 256\n",
      "The column 'Unnamed: 0' is not in dataframe 257\n",
      "The column 'Unnamed: 0' is not in dataframe 258\n",
      "The column 'Unnamed: 0' is not in dataframe 259\n",
      "The column 'Unnamed: 0' is not in dataframe 260\n",
      "The column 'Unnamed: 0' is not in dataframe 261\n",
      "The column 'Unnamed: 0' is not in dataframe 262\n",
      "The column 'Unnamed: 0' is not in dataframe 263\n",
      "The column 'Unnamed: 0' is not in dataframe 264\n",
      "The column 'Unnamed: 0' is not in dataframe 265\n",
      "The column 'Unnamed: 0' is not in dataframe 266\n",
      "The column 'Unnamed: 0' is not in dataframe 267\n",
      "The column 'Unnamed: 0' is not in dataframe 268\n",
      "The column 'Unnamed: 0' is not in dataframe 269\n",
      "The column 'Unnamed: 0' is not in dataframe 270\n",
      "The column 'Unnamed: 0' is not in dataframe 271\n",
      "The column 'Unnamed: 0' is not in dataframe 272\n",
      "The column 'Unnamed: 0' is not in dataframe 273\n",
      "The column 'Unnamed: 0' is not in dataframe 274\n",
      "The column 'Unnamed: 0' is not in dataframe 275\n",
      "The column 'Unnamed: 0' is not in dataframe 276\n",
      "The column 'Unnamed: 0' is not in dataframe 277\n",
      "The column 'Unnamed: 0' is not in dataframe 278\n",
      "The column 'Unnamed: 0' is not in dataframe 279\n",
      "The column 'Unnamed: 0' is not in dataframe 280\n",
      "The column 'Unnamed: 0' is not in dataframe 281\n",
      "The column 'Unnamed: 0' is not in dataframe 282\n",
      "The column 'Unnamed: 0' is not in dataframe 283\n",
      "The column 'Unnamed: 0' is not in dataframe 284\n",
      "The column 'Unnamed: 0' is not in dataframe 285\n",
      "The column 'Unnamed: 0' is not in dataframe 286\n",
      "The column 'Unnamed: 0' is not in dataframe 287\n",
      "The column 'Unnamed: 0' is not in dataframe 288\n",
      "The column 'Unnamed: 0' is not in dataframe 289\n",
      "The column 'Unnamed: 0' is not in dataframe 290\n",
      "The column 'Unnamed: 0' is not in dataframe 291\n",
      "The column 'Unnamed: 0' is not in dataframe 292\n",
      "The column 'Unnamed: 0' is not in dataframe 293\n",
      "The column 'Unnamed: 0' is not in dataframe 294\n",
      "The column 'Unnamed: 0' is not in dataframe 295\n",
      "The column 'Unnamed: 0' is not in dataframe 296\n",
      "The column 'Unnamed: 0' is not in dataframe 297\n",
      "The column 'Unnamed: 0' is not in dataframe 298\n",
      "The column 'Unnamed: 0' is not in dataframe 299\n",
      "The column 'Unnamed: 0' is not in dataframe 300\n",
      "The column 'Unnamed: 0' is not in dataframe 301\n",
      "The column 'Unnamed: 0' is not in dataframe 302\n",
      "The column 'Unnamed: 0' is not in dataframe 303\n",
      "The column 'Unnamed: 0' is not in dataframe 304\n",
      "The column 'Unnamed: 0' is not in dataframe 305\n",
      "The column 'Unnamed: 0' is not in dataframe 306\n",
      "The column 'Unnamed: 0' is not in dataframe 307\n",
      "The column 'Unnamed: 0' is not in dataframe 308\n",
      "The column 'Unnamed: 0' is not in dataframe 309\n",
      "The column 'Unnamed: 0' is not in dataframe 310\n",
      "The column 'Unnamed: 0' is not in dataframe 311\n"
     ]
    }
   ],
   "source": [
    "data_formats = []\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "for i in range(data_count):\n",
    "    # First check to see if the website consolidated the data into a non-scrape\n",
    "    # -friendly version of the data table\n",
    "    if (len(data_dfs[i].columns) == 3):\n",
    "        record_date = data_dfs[i]['Record Date'][0]\n",
    "        test_df = pd.DataFrame(columns=(data_dfs[i].loc[0, 1].split(',')))\n",
    "        \n",
    "        for j in range(1, data_dfs[i].count().max()):\n",
    "            test_df.append(data_dfs[i].loc[j, 1].split(','))\n",
    "\n",
    "        test_df['Record Date'] = [record_date]*test_df.count().max()\n",
    "        data_dfs[i] = test_df\n",
    "\n",
    "    # Now remove any unwanted columns\n",
    "    try:\n",
    "        data_dfs[i] = data_dfs[i].drop(columns='Unnamed: 0')\n",
    "    except KeyError:\n",
    "        print(f\"The column 'Unnamed: 0' is not in dataframe {i}\")\n",
    "\n",
    "    try:\n",
    "        data_dfs[i] = data_dfs[i].drop(columns='FIPS')\n",
    "    except KeyError:\n",
    "        print(f\"The column 'FIPS' is not in dataframe {i}\")\n",
    "\n",
    "    # Next, rename the columns for consitency\n",
    "    data_dfs[i] = data_dfs[i].rename(\n",
    "        columns={\n",
    "            \"Province_State\" : \"State\",\n",
    "            \"Province/State\" : \"State\",\n",
    "            \"Country_Region\" : \"Country\",\n",
    "            \"Country/Region\" : \"Country\",\n",
    "            \"Last_Update\" : \"Last Update\",\n",
    "            \"Lat\" : \"Latitude\",\n",
    "            \"Long_\" : \"Longitude\",\n",
    "            \"Case-Fatality_Ratio\" : \"Case-Fatality Ratio\",\n",
    "            \"Case_Fatality_Ratio\" : \"Case-Fatality Ratio\",\n",
    "            \"Incident_Rate\" : \"Incident Rate\",\n",
    "            \"Incidence_Rate\" : \"Incident Rate\",\n",
    "            'Admin2' : 'County',\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Finally, remove any row from the DF that isn't US data\n",
    "    data_dfs[i] = data_dfs[i].loc[data_dfs[i]['Country'] == 'US']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Put it all in one DataFrame (and Save to CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Record Date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>County</th>\n",
       "      <th>Active</th>\n",
       "      <th>Combined_Key</th>\n",
       "      <th>Incident Rate</th>\n",
       "      <th>Case-Fatality Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-22-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>1/23/20 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-23-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>1/24/20 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-24-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>US</td>\n",
       "      <td>1/24/20 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-24-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Washington</td>\n",
       "      <td>US</td>\n",
       "      <td>1/25/20 17:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-25-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-09-28 04:23:00</td>\n",
       "      <td>289.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>09-27-2020</td>\n",
       "      <td>44.790489</td>\n",
       "      <td>-106.886239</td>\n",
       "      <td>Sheridan</td>\n",
       "      <td>285.0</td>\n",
       "      <td>Sheridan, Wyoming, US</td>\n",
       "      <td>948.007217</td>\n",
       "      <td>1.384083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-09-28 04:23:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>09-27-2020</td>\n",
       "      <td>42.765583</td>\n",
       "      <td>-109.913092</td>\n",
       "      <td>Sublette</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Sublette, Wyoming, US</td>\n",
       "      <td>986.674804</td>\n",
       "      <td>1.030928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-09-28 04:23:00</td>\n",
       "      <td>335.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>09-27-2020</td>\n",
       "      <td>41.659439</td>\n",
       "      <td>-108.882788</td>\n",
       "      <td>Sweetwater</td>\n",
       "      <td>333.0</td>\n",
       "      <td>Sweetwater, Wyoming, US</td>\n",
       "      <td>791.157925</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-09-28 04:23:00</td>\n",
       "      <td>554.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>09-27-2020</td>\n",
       "      <td>43.935225</td>\n",
       "      <td>-110.589080</td>\n",
       "      <td>Teton</td>\n",
       "      <td>553.0</td>\n",
       "      <td>Teton, Wyoming, US</td>\n",
       "      <td>2361.063757</td>\n",
       "      <td>0.180505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>2020-09-28 04:23:00</td>\n",
       "      <td>352.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>09-27-2020</td>\n",
       "      <td>41.287818</td>\n",
       "      <td>-110.547578</td>\n",
       "      <td>Uinta</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Uinta, Wyoming, US</td>\n",
       "      <td>1740.334223</td>\n",
       "      <td>0.568182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           State Country          Last Update  Confirmed  Deaths  Recovered  \\\n",
       "31    Washington      US      1/22/2020 17:00        1.0     NaN        NaN   \n",
       "31    Washington      US        1/23/20 17:00        1.0     NaN        NaN   \n",
       "33    Washington      US        1/24/20 17:00        1.0     NaN        NaN   \n",
       "34       Chicago      US        1/24/20 17:00        1.0     NaN        NaN   \n",
       "33    Washington      US        1/25/20 17:00        1.0     NaN        NaN   \n",
       "...          ...     ...                  ...        ...     ...        ...   \n",
       "3896     Wyoming      US  2020-09-28 04:23:00      289.0     4.0        0.0   \n",
       "3897     Wyoming      US  2020-09-28 04:23:00       97.0     1.0        0.0   \n",
       "3898     Wyoming      US  2020-09-28 04:23:00      335.0     2.0        0.0   \n",
       "3899     Wyoming      US  2020-09-28 04:23:00      554.0     1.0        0.0   \n",
       "3900     Wyoming      US  2020-09-28 04:23:00      352.0     2.0        0.0   \n",
       "\n",
       "     Record Date   Latitude   Longitude      County  Active  \\\n",
       "31    01-22-2020        NaN         NaN         NaN     NaN   \n",
       "31    01-23-2020        NaN         NaN         NaN     NaN   \n",
       "33    01-24-2020        NaN         NaN         NaN     NaN   \n",
       "34    01-24-2020        NaN         NaN         NaN     NaN   \n",
       "33    01-25-2020        NaN         NaN         NaN     NaN   \n",
       "...          ...        ...         ...         ...     ...   \n",
       "3896  09-27-2020  44.790489 -106.886239    Sheridan   285.0   \n",
       "3897  09-27-2020  42.765583 -109.913092    Sublette    96.0   \n",
       "3898  09-27-2020  41.659439 -108.882788  Sweetwater   333.0   \n",
       "3899  09-27-2020  43.935225 -110.589080       Teton   553.0   \n",
       "3900  09-27-2020  41.287818 -110.547578       Uinta   350.0   \n",
       "\n",
       "                 Combined_Key  Incident Rate  Case-Fatality Ratio  \n",
       "31                        NaN            NaN                  NaN  \n",
       "31                        NaN            NaN                  NaN  \n",
       "33                        NaN            NaN                  NaN  \n",
       "34                        NaN            NaN                  NaN  \n",
       "33                        NaN            NaN                  NaN  \n",
       "...                       ...            ...                  ...  \n",
       "3896    Sheridan, Wyoming, US     948.007217             1.384083  \n",
       "3897    Sublette, Wyoming, US     986.674804             1.030928  \n",
       "3898  Sweetwater, Wyoming, US     791.157925             0.597015  \n",
       "3899       Teton, Wyoming, US    2361.063757             0.180505  \n",
       "3900       Uinta, Wyoming, US    1740.334223             0.568182  \n",
       "\n",
       "[397506 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = pd.DataFrame()\n",
    "\n",
    "for df in data_dfs:\n",
    "    main_df = main_df.append(df)\n",
    "\n",
    "main_df.to_csv('Data/US_Data.csv')\n",
    "\n",
    "main_df.head(-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
